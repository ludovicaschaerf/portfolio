import './polyfills.server.mjs';
import{A as x,D as w,a as l,b as h,c as p,d as t,e as i,f as n,g as e,h as c,o as u,q as f,r as g,s as b,t as v,w as y}from"./chunk-JMWOEWD5.mjs";var S=(()=>{let a=class a{constructor(){this.title="portfolio"}};a.\u0275fac=function(r){return new(r||a)},a.\u0275cmp=l({type:a,selectors:[["app-root"]],standalone:!0,features:[c],decls:15,vars:0,consts:[[1,"row","justify-content-center"],[1,"col-8","col-sm-5","col-lg-8"],[1,"navbar","navbar-expand-lg","navbar-light","justify-content-between","mr-2","mt-4"],["href","",2,"text-decoration","none"],[2,"font-size","23px"],[1,"justify-content-right"],[1,"navbar-nav","mx-auto"],[1,"nav-item"],["href","about",1,"nav-link",2,"font-family","didot","font-size","16px","color","black"],["href","publications",1,"nav-link",2,"font-family","didot","font-size","16px","color","black"]],template:function(r,d){r&1&&(t(0,"div",0)(1,"div",1)(2,"nav",2)(3,"a",3)(4,"h3",4),e(5," Ludovica Schaerf "),i()(),t(6,"div",5)(7,"ul",6)(8,"li",7)(9,"a",8),e(10," About "),i()(),t(11,"li",7)(12,"a",9),e(13," Publications & Resources "),i()()()()()()(),n(14,"router-outlet"))},dependencies:[f,x]});let o=a;return o})();var E=(()=>{let a=class a{constructor(s){this.titleService=s}ngOnInit(){this.titleService.setTitle("Ludovica Schaerf")}};a.\u0275fac=function(r){return new(r||a)(p(b))},a.\u0275cmp=l({type:a,selectors:[["app-home"]],decls:82,vars:0,consts:[[1,"row","justify-content-center"],[1,"row","justify-content-center","pt-5"],[1,"col-8","col-sm-5","col-lg-8"],[1,"row","justify-content-center","pt-5","pb-3"],["id","bg",1,"col-sm-5","col-md-2","col-lg-3",2,"text-align","left"],["href","generative-ai",2,"text-decoration","none"],["src","assets/images/textaile_cover.png","alt","generative AI","height","90%","width","100%"],[1,"overlay",2,"top","15%"],["id","bg",1,"col-sm-1","col-md-1","col-lg-1",2,"text-align","left"],["id","bg",1,"col-sm-5","col-md-3","col-lg-3",2,"text-align","left"],["href","critical-ai",2,"text-decoration","none"],["src","assets/images/textaile_critical.png","alt","critical AI","height","40%","width","100%"],[1,"overlay",2,"top","10%"],["width","100%","height","50%",2,"border-style","dashed none none none","border-width","2px","border-color","lightgray"],["href","critical-ai",1,"click"],[1,"material-icons"],["href","generative-ai",1,"click"],[1,"row","justify-content-center","pt-2","pb-3"],["id","bg",1,"col-8","col-sm-5","col-lg-3",2,"text-align","left"],["href","ai-curation",2,"text-decoration","none"],["src","assets/images/ai_curation.png","alt","AI Curation","height","80%","width","100%"],[1,"col-8","col-sm-5","col-lg-2","pt-3","pe-4"],["width","100%","height","70%",2,"border-style","dashed none none none","border-width","2px","border-color","lightgray"],["href","ai-curation",1,"click"],["href","calvino",1,"click",2,"text-decoration","none"],["href","calvino",2,"text-decoration","none"],["src","assets/images/calvino1.png","alt","Multimodal","height","80%","width","100%"],[1,"overlay",2,"top","40%"],["href","art-authentication",2,"text-decoration","none"],["src","assets/images/modigliani_gan.png","alt","AI Art Authentication","height","120%","width","100%"],[1,"overlay",2,"top","35%"],[1,"col-8","col-sm-5","col-lg-3"],["href","art-authentication",1,"click"],[1,"col-8","col-sm-5","col-lg-2"]],template:function(r,d){r&1&&(t(0,"div",0)(1,"div",1)(2,"div",2)(3,"b"),e(4,"Main Projects"),i(),n(5,"br"),e(6," This portfolio of works presents a selection of projects divided into macro categories following my main fields of interest. "),i()(),t(7,"div",3)(8,"div",4)(9,"a",5),n(10,"img",6),t(11,"div",7),e(12,"Generative AI"),i()()(),n(13,"div",8),t(14,"div",9)(15,"a",10),n(16,"img",11),t(17,"div",12),e(18,"Critical Computer Vision"),i(),t(19,"div",13),n(20,"br"),t(21,"p")(22,"a",14)(23,"span",15),e(24," expand_less "),i(),t(25,"b"),e(26,"Critical AI: Philosophy, Arts, Tech and Critical Studies"),i(),e(27," On the latent space from a philosophical and creative perspective. "),i()(),t(28,"p")(29,"a",16)(30,"span",15),e(31," chevron_left "),i(),t(32,"b"),e(33,"Generative AI: Representation learning, Disentanglement"),i(),e(34," Delving into vision AI's representations of colors in textiles. "),i()()()()()(),t(35,"div",17)(36,"div",18)(37,"a",19),n(38,"img",20),t(39,"div",7),e(40," AI Art Curation "),i()()(),t(41,"div",21)(42,"div",22),n(43,"br"),t(44,"p")(45,"span",15),e(46," chevron_left "),i(),t(47,"a",23)(48,"b"),e(49,"AI Art Curation"),i(),e(50,". Reviving data and recreating art in the city of Helsinki. "),i()(),t(51,"p")(52,"a",24)(53,"b"),e(54,"Latent Atlas of Calvino's Citt\xE0 Invisibili"),i(),e(55,". Re-imagining Kublai Khan's Atlas as a multimodal latent space. "),t(56,"span",15),e(57," chevron_right "),i()()()()(),t(58,"div",18)(59,"a",25),n(60,"img",26),t(61,"div",27),e(62,"Multimodal AI"),i()()()(),t(63,"div",3)(64,"div",4)(65,"a",28),n(66,"img",29),t(67,"div",30),e(68,"AI Art "),n(69,"br"),e(70,"Authentication"),i()()(),t(71,"div",31)(72,"div",22),n(73,"br"),t(74,"p")(75,"span",15),e(76," chevron_left "),i(),t(77,"a",32)(78,"b"),e(79,"AI Art Authentication"),i(),e(80,". Does AI get a say as an Art Connoisseur, Art Critic or Art Historian? "),i()()()(),n(81,"div",33),i()())}});let o=a;return o})();var A=(()=>{let a=class a{};a.\u0275fac=function(r){return new(r||a)},a.\u0275cmp=l({type:a,selectors:[["app-calvino"]],standalone:!0,features:[c],decls:55,vars:0,consts:[[1,"row","justify-content-center"],[1,"col-8","col-md-3"],[2,"text-align","left"],[2,"border-style","dashed none none none","border-width","2px","border-color","lightgray"],["src","assets/images/ondine.jpg","height","450","width","100%",2,"padding-top","20px"],[2,"font-size","12px"],["href","https://commons.wikimedia.org/wiki/File:Arthur_Rackham_1909_Undine_(14_of_15).jpg"],[1,"col-8","col-md-5","ps-5"],["width","100%","height","70%"],["href","https://www.nature.com/articles/s41599-023-01796-7"],["href","https://github.com/DCMLab/debussy_piano"],[1,"row","justify-content-center","mt-5","pb-5",2,"background-color","#ccb98f"],[1,"col-5","pt-5"],["src","assets/images/debussy_presentation.png","height","250","width","100%",2,"float","left","padding-top","20px"],[1,"col-8"],[2,"color","black"]],template:function(r,d){r&1&&(t(0,"div",0)(1,"div",1),n(2,"br"),t(3,"h5",2),e(4,"Debussy's Tonal Ambiguity"),i(),t(5,"p",2),e(6," Project done in 2021-2022 "),n(7,"br"),e(8," for the Digital Musicology class "),n(9,"br"),e(10," at EPFL "),n(11,"br"),i(),t(12,"div",3),n(13,"br"),i(),n(14,"img",4),t(15,"p",5),e(16,"Arthur Rackham (1909). Undine. From "),t(17,"a",6),e(18,"here"),i()(),n(19,"br"),i(),t(20,"div",7)(21,"div",8)(22,"p",2),n(23,"br"),t(24,"em"),e(25,"To be honest, I know more or less nothing about musicology, and I am certainly not the one in the team who's behind the topic selection. After a rough start at this project, as the semester went by, all of a sudden, dozens of methods to quantify tonal ambiguity started coming to our minds. It was a really great feeling: I could put numbers and draw conclusions on something I could understand so poorly myself. After this, the two TA's of the course offered to help to turn this into a paper. They helped so much and I am so grateful. We have presented this work at two conferences and the full paper has been published on Nature Humanities and Social Sciences. We even won the best poster presentation award! Below, the abstract of the project and the link to the full text: "),i(),n(26,"br")(27,"br"),e(28," Claude Debussy\u2019s personal style is typically characterised as a departure from earlier diatonic tonality, including a greater variety of pitch-class materials organised in fragmented yet coherent compositions. Exploiting the music-theoretical interpretability of Discrete Fourier Transforms over pitch-class distributions, we performed a corpus study over Debussy\u2019s solo-piano works in order to investigate the diachronic development of such stylistic features across the composer\u2019s lifespan. We propose quantitative heuristics for the prevalence of different pitch-class prototypes, the fragmentation of a piece across different prototypes, as well as some aspect of the overall coherence of a piece. We found strong evidence for a decrease of diatonicity in favour of octatonicity, as well as for an increase of fragmentation accompanied by non-decreasing coherence. These results contribute to the understanding of the historical development of extended-tonal harmony, while representing a fertile testing ground for the interaction of computational corpus-based methods with traditional music analytical approaches. "),n(29,"br")(30,"br")(31,"br"),t(32,"b"),e(33,"For the full text: "),i(),t(34,"a",9),e(35," here"),i(),e(36,". "),n(37,"br"),t(38,"b"),e(39,"For the code: "),i(),t(40,"a",10),e(41," here"),i(),e(42,". "),i()()(),t(43,"div",11)(44,"div",12),n(45,"img",13)(46,"br"),t(47,"p",5),e(48,"Debussy. Ondine. From Wavescapes to Summary Wavescape (Visualization by Sabrina Laneve)"),i()(),t(49,"div",14)(50,"p",15),n(51,"br"),t(52,"em"),e(53,"An excerpt from our case studies: "),i(),e(54,'This piece marks "one of Debussy\u2019s most extreme essays in discontinuity", painting a picture of ambiguity: it consists of gestures and motivic cells more than themes, all of them frequently juxtaposed without any continuity. The different sections are often outside of a clear key centre. However, under the surface of seemingly fragmented music lies a meticulously organised construction. Functional relationships dissolve and become subordinate to new pitch-set interactions. This occurs not as a programmatic purpose of explicitly rejecting tonality but instead as a consequence of the colours, sonorities, moods employed to evoke the "Ondine"\u2019s character. Referring to "Ondines", Anthony Aubrey Tobin states: "The dichotomy between real and imaginary realms ascribed to mythology is a symbolic link to the conflict between vestigial references to tonality and total dissolution." This contrast is musically represented on different layers. The piece is based on the conflict between the two whole-tone scale poles and between related octatonic segments. Utilising common pitches and introducing extraneous notes in scale fragments, the music moves to different pitch sets to create new means of forward motion. Combining the two poles and octatonic sets determines the emergence of the diatonic sets, such as the D-Lydian lyrical theme (interpretable as a fusion of the two whole tone poles: D-E-F-G + A-B-C) or the final D section. On a large scale, the piece exhibits symmetrical Rondo form, arising from the combination of octatonic and whole-tone structures, which expresses the contrast between the natural and supernatural world. '),i()()()())}});let o=a;return o})();var C=(()=>{let a=class a{};a.\u0275fac=function(r){return new(r||a)},a.\u0275cmp=l({type:a,selectors:[["app-ai-curation"]],standalone:!0,features:[c],decls:47,vars:0,consts:[[1,"row","justify-content-center","mt-5","pb-5",2,"background-color","#d27672"],[1,"col-8"],["src","assets/images/helsinki.gif","height","450","width","100%",2,"float","left","padding-top","20px"],[2,"font-size","12px"],[1,"row","justify-content-center"],[1,"col-8","col-md-3"],[2,"text-align","left"],[2,"border-style","dashed none none none","border-width","2px","border-color","lightgray"],[1,"col-8","col-md-5","ps-5"],["width","100%","height","70%"],["href","https://arxiv.org/abs/2306.03753"],["href","http://newlyformedcity.net/"],[1,"row","justify-content-center","mt-5","pb-5",2,"background-color","black"],["src","assets/images/helsinki2.gif","height","450","width","100%",2,"float","left","padding-top","20px"]],template:function(r,d){r&1&&(t(0,"div",0)(1,"div",1),n(2,"img",2),t(3,"p",3),e(4,"Transformation of a location in Helsinki into an artwork by a local artist that our model predicts to belong to that location."),i()()(),t(5,"div",4)(6,"div",5),n(7,"br"),t(8,"h5",6),e(9,"Newly Formed Cities"),i(),t(10,"p",6),e(11," Project done in 2023 "),n(12,"br"),e(13," as part of my PhD "),n(14,"br"),e(15," at Digital Visual Studies (MPG-UZH) "),n(16,"br"),i(),n(17,"div",7),i(),t(18,"div",8)(19,"div",9)(20,"p",6),n(21,"br"),t(22,"em"),e(23," This project was my first experience entering the world of artistic practices. We worked with the DVS team on this installation for the Helsinki Biennial of 2023, where we asked to create an AI curation of the Helsinki Art Museum. We did so reimagining the space of Helsinki as an installation ground where the space merges into the art. We presented this work at EC3V (workshop at CVPR) where we won best presentation! And the full journal article has been submitted for publication. Here is its abstract: "),i(),n(24,"br")(25,"br"),e(26," Art curatorial practice involves presenting an art collection in a knowledgeable way. Machine processes, on the other hand, are characterized by their ability to manage and analyze vast amounts of data. This paper explores the implications of contemporary machine learning models for the curatorial world through AI curation and audience interaction. The project was developed for the 2023 Helsinki Art Biennial, titled \u201DNew Directions May Emerge,\u201D and utilizes the Helsinki Art Museum (HAM) collection to re-imagine the city of Helsinki through the lens of machine perception. Visual-textual models are used to place museum artworks in public spaces, assigning fictional coordinates based on similarity scores. They are then employed to generate synthetic 360\xB0 art panoramas, transforming the space that each artwork inhabits in the city. The generation is guided by estimated depth values from 360\xB0 panoramas at each artwork location and using machine- generated prompts of the artworks. The result is an AI curation that places the artworks in their imagined physical space, blurring the lines of artwork, context, and machine perception. The project is virtually presented as a multimedia web- based installation, where users can navigate an alternative version of the city and explore and interact with its cultural heritage at scale. "),n(27,"br")(28,"br")(29,"br"),t(30,"b"),e(31,"For the full text:"),i(),t(32,"a",10),e(33," here"),i(),e(34,". "),n(35,"br"),t(36,"b"),e(37,"For the website:"),i(),t(38,"a",11),e(39," here"),i(),e(40,". "),i()()(),t(41,"div",12)(42,"div",1),n(43,"img",13)(44,"br"),t(45,"p",3),e(46,"Example panoramas.The original artworks - on the right - start to inhabit the space (Visualization by Iacopo Neri)"),i()()()())}});let o=a;return o})();var D=(()=>{let a=class a{};a.\u0275fac=function(r){return new(r||a)},a.\u0275cmp=l({type:a,selectors:[["app-critical-ai"]],standalone:!0,features:[c],decls:54,vars:0,consts:[["src",h`https://neriiacopo.github.io/LatentSpaceNavigator/`,2,"width","100%","height","40vw"],[1,"row","justify-content-center"],[1,"col-8","col-md-3"],[2,"text-align","left"],[2,"border-style","dashed none none none","border-width","2px","border-color","lightgray"],["src","assets/images/textaile.png","height","350","width","100%",2,"padding-top","20px"],[2,"font-size","12px"],[1,"col-8","col-md-5","ps-5"],["width","100%","height","70%"],[1,"row","justify-content-center","mt-5","pb-5",2,"background-color","#f7e20d"],[1,"col-8"],["src","assets/images/cudan.png","height","100%","width","100%",2,"float","left","padding-top","20px"],[1,"row","justify-content-center",2,"background-color","#f7e20d"],["href","https://textaile-disentangled-color-directions.my.canva.site/"],["href","https://www.youtube.com/watch?v=erkg5nB-4eE"]],template:function(r,d){r&1&&(n(0,"embed",0),t(1,"div",1)(2,"div",2),n(3,"br"),t(4,"h5",3),e(5,"Augmenting Explainable AI "),n(6,"br"),e(7," The Latent Space of Large Vision Models through Interpretative Artistic Dimensions "),i(),t(8,"p",3),e(9," This is my main project "),n(10,"br"),e(11," for my PhD (2023-) "),n(12,"br"),e(13," at Digital Visual Studies (MPG-UZH) "),n(14,"br"),i(),t(15,"div",4),n(16,"br"),i(),n(17,"img",5),t(18,"p",6),e(19,"Schematization of the disentangled directions in the latent space. The arrows indicate vectors of disentangled color directions, and the images are the textile samples generated by the model at those points. We see that movement in those directions yields appropriate changes in color. "),i(),n(20,"br"),i(),t(21,"div",7)(22,"div",8)(23,"p",3),n(24,"br"),t(25,"em"),e(26,"This is the project proposal for my PhD. The project aims to provide a framework to improve understanding of the latent spaces of vision and text-vision generative models. I believe the spaces are filled with important information on the functioning of the models (the distorted lens of AI models) and on the cultural and societal appropriations of these models from their training data. While latent space analyses have gained large popularity, there is still lots to discover on how to understand and exploit these spaces. Broadly speaking, it is aimed at providing an interpretation of a selection of concepts related to artistic and design practices as represented within the latent spaces of artificial intelligence models. "),i(),n(27,"br")(28,"br"),t(29,"b"),e(30,"Color Disentanglement of Textile Patterns"),i(),e(31,` We investigate the potential of the use of disentanglement to provide a - reductionist - understanding of abstract concepts in deep learning models. Disentanglement is defined in computer vision as the task of learning or identifying traversal directions in the latent space of models controlling only one factor of variation. The method is central to image manipulation techniques but is also used for explainable AI and style transfer.
We focus on the interpretative potential. We train several models (BetaVAE, StyleGAN3, Stable Diffusion) on the Metropolitan and the V&A textile collections to generate synthetic textile samples. The first aim is threefold. We first aim to correctly train at least one of the proposed models on a large enough dataset of textile patterns to be able to generate a variety of plausible synthetic textile samples. We secondly aim to enforce qualities that are crucial in textile pattern generation, first and foremost, the repeat. The generated textile samples need to be suitable for real-life printing and thus need to be stackable into a cloth, thus avoiding discontinuities in lateral and vertical stacking. Lastly, as in human textile sample generation, we need to be able to provide a colorway that accompanies each textile, where in addition to the base color of each pattern, we can automatically adapt the pattern into 4 main color variations. We aim to achieve this latter using color disentanglement. We hypothesize that AI-based color manipulation may yield colorways that respect - to some extent \u2013 color theory and color harmony principles but enable larger variability, while image processing-based hue manipulation would only shift the colors in a single direction.
Secondly, by finetuning these models on certain periods of time, such as the English textile scene of the post-London Expo of 1851 and 62, the Rubelli, Bevilacqua, and Fortuny Venetian textiles, or the Bauhaus textile artists and artisans, we aim to compare the difference in color generation and adaptation that are possible within these \u2013 partially - circumscribed frameworks. We, therefore, wish to use latent space navigation as a means of cultural and art historical investigation on the consuetudes that link to color in each period. The combination of these two steps should help to augment explainable AI towards interpretable AI, where domain knowledge can be used to accompany observations. `),n(32,"br"),t(33,"b"),e(34,"Disentangled Abstractions or Verbalization Conditioning"),i(),e(35,` The recent hype for multimodal models gave rise to a novel entry point to latent spaces: language conditioning. While disentanglement is obtained backward from the image, and it is thus vision-first, text conditioning often stems from a pre-trained language backbone and is thus language-first. This second part of the project focuses on qualifying the technical and semantic differences between language conditioning and disentangled directions for image manipulation.
We first aim to survey and compare the different techniques that are visual-first from language-first, comparing their effect on the images and on the latent spaces of the models.
Arguably, art history is a narration of art through text, and, similarly, visual sketches, prints, and photographic reproductions are at the foundation of its study. In this part, we would like to investigate which salient elements of art can be conveyed to the machine and in art history, using language or visual abstractions. `),i()()(),t(36,"div",9)(37,"div",10),n(38,"img",11)(39,"br"),t(40,"p",6),e(41,"First slide of a presentation given at CUDAN 2023 explaining the theoretical grounding and first methodology of the project."),i()()(),t(42,"div",12)(43,"div",10)(44,"p"),e(45,"The slides are available at the following "),t(46,"a",13),e(47,"link"),i(),e(48,"."),n(49,"br"),e(50,`
The presentation is available at the following `),t(51,"a",14),e(52,"link from minute 47"),i(),e(53,"."),i()()()())}});let o=a;return o})();var k=(()=>{let a=class a{};a.\u0275fac=function(r){return new(r||a)},a.\u0275cmp=l({type:a,selectors:[["app-generative-ai"]],standalone:!0,features:[c],decls:36,vars:0,consts:[[1,"row","justify-content-center","mt-5","pb-5"],[1,"col-8"],["src","assets/images/colorwai.gif","height","100%","width","100%",2,"float","left","padding-top","20px"],[1,"row","justify-content-center"],[1,"col-8","col-md-3"],[2,"text-align","left"],[2,"border-style","dashed none none none","border-width","2px","border-color","lightgray"],[1,"col-8","col-md-5","ps-5"],["width","100%","height","70%"]],template:function(r,d){r&1&&(t(0,"div",0)(1,"div",1),n(2,"img",2)(3,"br"),i()(),t(4,"div",3)(5,"div",4),n(6,"br"),t(7,"h5",5),e(8,"Augmenting Explainable AI "),n(9,"br"),e(10," The Latent Space of Large Vision Models through Interpretative Artistic Dimensions "),i(),t(11,"p",5),e(12," This is my main project "),n(13,"br"),e(14," for my PhD (2023-) "),n(15,"br"),e(16," at Digital Visual Studies (MPG-UZH) "),n(17,"br"),i(),t(18,"div",6),n(19,"br"),i(),n(20,"br"),i(),t(21,"div",7)(22,"div",8)(23,"p",5),n(24,"br"),t(25,"em"),e(26,"This is the project proposal for my PhD. The project aims to provide a framework to improve understanding of the latent spaces of vision and text-vision generative models. I believe the spaces are filled with important information on the functioning of the models (the distorted lens of AI models) and on the cultural and societal appropriations of these models from their training data. While latent space analyses have gained large popularity, there is still lots to discover on how to understand and exploit these spaces. Broadly speaking, it is aimed at providing an interpretation of a selection of concepts related to artistic and design practices as represented within the latent spaces of artificial intelligence models. "),i(),n(27,"br")(28,"br"),t(29,"b"),e(30,"Color Disentanglement of Textile Patterns"),i(),e(31,` We investigate the potential of the use of disentanglement to provide a - reductionist - understanding of abstract concepts in deep learning models. Disentanglement is defined in computer vision as the task of learning or identifying traversal directions in the latent space of models controlling only one factor of variation. The method is central to image manipulation techniques but is also used for explainable AI and style transfer.
We focus on the interpretative potential. We train several models (BetaVAE, StyleGAN3, Stable Diffusion) on the Metropolitan and the V&A textile collections to generate synthetic textile samples. The first aim is threefold. We first aim to correctly train at least one of the proposed models on a large enough dataset of textile patterns to be able to generate a variety of plausible synthetic textile samples. We secondly aim to enforce qualities that are crucial in textile pattern generation, first and foremost, the repeat. The generated textile samples need to be suitable for real-life printing and thus need to be stackable into a cloth, thus avoiding discontinuities in lateral and vertical stacking. Lastly, as in human textile sample generation, we need to be able to provide a colorway that accompanies each textile, where in addition to the base color of each pattern, we can automatically adapt the pattern into 4 main color variations. We aim to achieve this latter using color disentanglement. We hypothesize that AI-based color manipulation may yield colorways that respect - to some extent \u2013 color theory and color harmony principles but enable larger variability, while image processing-based hue manipulation would only shift the colors in a single direction.
Secondly, by finetuning these models on certain periods of time, such as the English textile scene of the post-London Expo of 1851 and 62, the Rubelli, Bevilacqua, and Fortuny Venetian textiles, or the Bauhaus textile artists and artisans, we aim to compare the difference in color generation and adaptation that are possible within these \u2013 partially - circumscribed frameworks. We, therefore, wish to use latent space navigation as a means of cultural and art historical investigation on the consuetudes that link to color in each period. The combination of these two steps should help to augment explainable AI towards interpretable AI, where domain knowledge can be used to accompany observations. `),n(32,"br"),t(33,"b"),e(34,"Disentangled Abstractions or Verbalization Conditioning"),i(),e(35,` The recent hype for multimodal models gave rise to a novel entry point to latent spaces: language conditioning. While disentanglement is obtained backward from the image, and it is thus vision-first, text conditioning often stems from a pre-trained language backbone and is thus language-first. This second part of the project focuses on qualifying the technical and semantic differences between language conditioning and disentangled directions for image manipulation.
We first aim to survey and compare the different techniques that are visual-first from language-first, comparing their effect on the images and on the latent spaces of the models.
Arguably, art history is a narration of art through text, and, similarly, visual sketches, prints, and photographic reproductions are at the foundation of its study. In this part, we would like to investigate which salient elements of art can be conveyed to the machine and in art history, using language or visual abstractions. `),i()()()())}});let o=a;return o})();var I=(()=>{let a=class a{};a.\u0275fac=function(r){return new(r||a)},a.\u0275cmp=l({type:a,selectors:[["app-art-authentication"]],standalone:!0,features:[c],decls:39,vars:0,consts:[[1,"row","justify-content-center"],[1,"col-8","col-md-3"],[2,"text-align","left"],[2,"border-style","dashed none none none","border-width","2px","border-color","lightgray"],[1,"col-8","col-md-5","ps-5"],["width","100%","height","70%"],["href","https://link.springer.com/article/10.1007/s00521-023-08864-8"],["href",""],[1,"row","justify-content-center","mt-5","pb-5",2,"background-color","white"],[1,"col-6","justify-content-center"],["src","assets/images/vangogh.png","height","700","width","100%",2,"padding-top","20px"]],template:function(r,d){r&1&&(t(0,"div",0)(1,"div",1),n(2,"br"),t(3,"h5",2),e(4,"Art Authentication with Computer Vision"),i(),t(5,"p",2),e(6," Project done in 2022-2023 "),n(7,"br"),e(8," as an R&D project "),n(9,"br"),e(10," at Art Recognition "),n(11,"br"),i(),n(12,"div",3),i(),t(13,"div",4)(14,"div",5)(15,"p",2),n(16,"br"),t(17,"em"),e(18," These projects were carried out when I was working as a Senior AI Developer in a Zurich-based start-up called Art Recognition. These were part of the several improvements that we made with the team to the AI-based Authentication techniques of the company. The research includes two publications, the first exploring the possibility of using Vision Transformers for art authentication and the second that of Generative AI. The first paper was published on Neural Computing and Applications and the second on PlosONE. What follows is the abstract of the second publication: "),i(),n(19,"br")(20,"br"),e(21," Previous research has shown that Artificial Intelligence is capable of distinguishing between authentic paintings by a given artist and human-made forgeries with remarkable accuracy, provided sufficient training. However, with the limited amount of existing known forgeries, augmentation methods for forgery detection are highly desirable. In this work, we examine the potential of incorporating synthetic artworks into training datasets to enhance the performance of forgery detection. Our investigation focuses on paintings by Vincent van Gogh, for which we release the first dataset specialized for forgery detection. To reinforce our results, we conduct the same analyses on the artists Amedeo Modigliani and Raphael. We train a classifier to distinguish original artworks from forgeries. For this, we use human-made forgeries and imitations in the style of well-known artists and augment our training sets with images in a similar style generated by Stable Diffusion and StyleGAN. We find that the additional synthetic forgeries consistently improve the detection of human-made forgeries. In addition, we find that, in line with previous research, the inclusion of synthetic forgeries in the training also enables the detection of AI-generated forgeries, especially if created using a similar generator. "),n(22,"br")(23,"br")(24,"br"),t(25,"b"),e(26,"For the full texts:"),i(),n(27,"br"),t(28,"a",6),e(29,"Vision Transformers vs CNNs"),i(),e(30,", "),n(31,"br"),t(32,"a",7),e(33,"Synthetic data (ACCEPTED FOR PUBLICATION)"),i(),e(34,". "),i()()(),t(35,"div",8)(36,"div",9),n(37,"img",10)(38,"br"),i()()())}});let o=a;return o})();var T=(()=>{let a=class a{};a.\u0275fac=function(r){return new(r||a)},a.\u0275cmp=l({type:a,selectors:[["app-resources"]],standalone:!0,features:[c],decls:144,vars:0,consts:[[1,"row","justify-content-center","pt-4"],["width","100%","height","100%",1,"col-8",2,"border-style","dashed none none none","border-width","2px","border-color","lightgray"],["href","https://arxiv.org/abs/2407.11514"],["href","https://doi.org/10.48550/arXiv.2306.03753"],["href","https://disegno.mome.hu/articles/Disegno_2023_I_06_Neri-et-al.pdf"],["href","https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0295967"],["href","https://doi.org/10.1007/s00521-023-08864-8"],["href","https://doi.org/10.1057/s41599-023-01796-7"],["href","https://doi.org/10.1145/3603163.3609083"],["href","https://www.canva.com/design/DAGFelsd1mk/_sSymdF9rh9y_HtTXVabuQ/view?utm_content=DAGFelsd1mk&utm_campaign=designshare&utm_medium=link&utm_source=editor"],["href","https://www.canva.com/design/DAF6o2Z08LE/Xz_j837XM2VtYLUF3FYH9w/view?utm_content=DAF6o2Z08LE&utm_campaign=designshare&utm_medium=link&utm_source=editor"],["href","https://www.youtube.com/watch?v=erkg5nB-4eE"],["href","https://docs.google.com/presentation/d/1FEKS_QFUVEMDtXC0FyeMdkALh-ynvbFxj70-p1sC4bA/edit?usp=sharing"],["href","https://helsinkibiennaali.fi/en/artist/yehwan-song/"],["href","https://dvstudies.net/2024/06/04/ai-and-computational-thinking-in-digital-art-history/"],["href","https://dvstudies.net/2024/01/25/colors-of-ai-computational-creativity/"]],template:function(r,d){r&1&&(t(0,"div",0)(1,"div",1),n(2,"br"),t(3,"p")(4,"b"),e(5,"Publications"),i()(),n(6,"br"),t(7,"p"),e(8,'"ColorwAI: Generative Colorways of Textiles through GAN and Diffusion Disentanglement" in VISART, ECCV 2024, oral presentation. DOI: '),t(9,"a",2),e(10,"https://arxiv.org/abs/2407.11514"),i(),e(11,". Ludovica Schaerf, Andrea Alfarano, Eric Postma, September 2024."),i(),n(12,"br"),t(13,"p"),e(14,'"Reflections on Disentanglement and the Latent Space" in xCoAx, School of X, 2024. Ludovica Schaerf. September 2024.'),i(),n(15,"br"),t(16,"p"),e(17,'"Art Forgery Detection using Kolmogorov Arnold and Convolutional Neural Networks", AI4VA, ECCV 2024. Sandro Boccuzzo, Desir\xE8e Meyer, Ludovica Schaerf. September 2024.'),i(),n(18,"br"),t(19,"p"),e(20,"\u201CAI Art Curation: Re-imagining the City of Helsinki on the Occasion of its Biennial\u201D, presented at EC3V, CVPR 2023, best paper award, DOI: "),t(21,"a",3),e(22,"https://doi.org/10.48550/arXiv.2306.03753"),i(),e(23,", Ludovica Schaerf*, Pepe Ballesteros*, Valentine Bernasconi*, Iacopo Neri*, and Dario Negueruela del Castillo*, under review."),i(),n(24,"br"),t(25,"p"),e(26,"\u201CNew Directions May Emerge: AI Curation of Helsinki\u2019s Cultural Landscape\u201D, in Disegno MOME, special issue on \u201CDesigning Digital Humanities\u201D, DOI: "),t(27,"a",4),e(28,"https://disegno.mome.hu/articles/Disegno_2023_I_06_Neri-et-al.pdf"),i(),e(29,", Dar\xEDo Negueruela del Castillo*, Iacopo Neri*, Pepe Ballesteros Zapata*, Valentine Bernasconi*, and Ludovica Schaerf*, December 2023."),i(),n(30,"br"),t(31,"p"),e(32,"\u201CSynthetic images aid the recognition of human-made art forgeries\u201D, in PLOS ONE. DOI:"),t(33,"a",5),e(34,"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0295967"),i(),e(35,". Johann Ostmeyer*, Ludovica Schaerf*, Pavel Buividovich, Tessa Charles, and Carina Popovici, January 2024."),i(),n(36,"br"),t(37,"p"),e(38,'\u201CArt Authentication with Vision Transformers\u201D, in Springer for Neural Computing and Applications, special issue on "Topical Collection on Visual Pattern Recognition and Extraction for Cultural Heritage", DOI: '),t(39,"a",6),e(40,"https://doi.org/10.1007/s00521-023-08864-8"),i(),e(41,", Ludovica Schaerf, Eric Postma, and Carina Popovici, July 2023."),i(),n(42,"br"),t(43,"p"),e(44,"\u201CThe diachronic development of Debussy\u2019s musical style: a corpus study with Discrete Fourier Transform\u201D in Nature Humanities and Social Sciences Communications, DOI: "),t(45,"a",7),e(46,"https://doi.org/10.1057/s41599-023-01796-7"),i(),e(47,", Sabrina Laneve*, Ludovica Schaerf*, Gabriele Cecchetti*, Johannes Hentschel*, and Martin Rohrmeier, June 2023. "),i(),n(48,"br"),t(49,"p"),e(50,"\u201CTranshistorical Urban Landscape as Hypermap\u201D, in ACM Conference on Hypertext and Social Media (HT2023), DOI: "),t(51,"a",8),e(52,"https://doi.org/10.1145/3603163.3609083"),i(),e(53,", Dario Negueruela del Castillo*, Iacopo Neri*, Paul Guhennec*, Ludovica Schaerf*, Valentine Bernasconi*, and Pepe Ballesteros Zapata*, September 2023."),i(),n(54,"br"),t(55,"p"),e(56,"* Indicates equal contribution."),i(),n(57,"div",1)(58,"br"),t(59,"p")(60,"b"),e(61,"Talks"),i()(),n(62,"br"),t(63,"p"),e(64,"\u201CDisentanglement, the Multi-dimensional Archive, and the Use of Color in Textile Samples\u201D, in School of X, xCoAx 2024. Fabrica, Italy, 13.07.24. "),t(65,"a",9),e(66,"Link to slides"),i(),e(67,"."),i(),n(68,"br"),t(69,"p"),e(70,"\u201CTextAIles: Color Manipulations in the Latent Space of StyleGAN3\u201D, in Computer Vision and Image Analysis of Art, Electronic Imaging 2024. San Francisco, United States, 21-25.01.24. "),t(71,"a",10),e(72,"Link to slides"),i(),e(73,"."),i(),n(74,"br"),t(75,"p"),e(76,"\u201CDo Computer Vision models internally differentiate visual and conceptual aspects of art without explicit supervision?\u201D. Cultural Data Analytics Conference 2023 (CUDAN 2023), Tallinn, Estonia, 13-16.12.2023. "),t(77,"a",11),e(78,"Link to video presentation"),i(),e(79,"."),i(),n(80,"br"),t(81,"p"),e(82,"\u201CTranshistorical Urban Landscape as Hypermap\u201D. ACM Conference on Hypertext and Social Media (HT2023), Max-Plank-Institut f\xFCr Kunstgeschichte, Villino Stroganoff, Rome, Italy, 06.09.2023."),i(),n(83,"br"),t(84,"p"),e(85,"\u201CDisentanglement: Inside Single Concepts of AI\u201D. Workshop \u201CTowards a Collaborative Cultural Analysis of the City of Rome\u201D, organized by Bibliotheca Hertziana Max-Plank-Institut f\xFCr Kunstgeschichte, Villino Stroganoff, Rome, Italy, 26-28.06.2023."),i(),n(86,"br"),t(87,"p"),e(88,"\u201CTowards AI Art Curation: Re-imagining the city of Helsinki on the occasion of its Biennial\u201D. CVPR workshop on \u201CEthical Considerations in Creative Applications of Computer Vision\u201D (EC3V), Vancouver, United States, 18.06.2023. "),t(89,"a",12),e(90,"Link to slides"),i(),e(91,"."),i(),n(92,"br"),t(93,"p"),e(94,`\u201CSynthetic Data in Art Historical Datasets? Considerations from the Case Study on Art Authentication\u201D. Symposium \u201CFrom Hype to Reality: Artificial Intelligence in the Study of Art and Culture,\u201D organized by Digital Society Initiative and Digital Visual Studies, Zurich, Switzerland, 20-21.04.2023.
`),i(),n(95,"div",1)(96,"br"),t(97,"p")(98,"b"),e(99,"Art Projects"),i()(),n(100,"br"),t(101,"p"),e(102,"\u201CNewly Formed City\u201D, AI art curation for the Helsinki Biennial 2023. With Iacopo Neri, Dario Negueruela del Castillo, "),t(103,"a",13),e(104,"Yehwan Song"),i(),e(105,", Pepe Ballesteros Zapata, Valentine Bernasconi."),i(),n(106,"br"),t(107,"p"),e(108,"\u201CCollection Translator\u201D, AI art curation for the Mambo Museum Bogot\xE0 2024. With Ana Zapata, Iacopo Neri, Dario Negueruela del Castillo, Pepe Ballesteros Zapata, Andrea Alfarano."),i(),n(109,"br")(110,"div",1)(111,"br"),t(112,"p")(113,"b"),e(114,"Lecturing"),i()(),n(115,"br"),t(116,"p"),e(117,"\u201CAI and Computational Thinking in Digital Art History\u201D, 6 credits seminar. With Pepe Ballesteros Zapata and Dario Negueruela del Castillo. University of Zurich, Spring 2024. Three papers from student projects were submitted for publication! "),t(118,"a",14),e(119,"More info"),i(),e(120,"."),i(),n(121,"br")(122,"div",1)(123,"br"),t(124,"p")(125,"b"),e(126,"Organization"),i()(),n(127,"br"),t(128,"p"),e(129,"\u201CColors of AI\u201D, workshop at International Conference on Computational Creativity. With Piera Riccio, Dejan Grba, Dario Negueruela del Castillo, Nurial Oliver. Jonkoping, Sweden, June 2024. "),t(130,"a",15),e(131,"Webpage"),i(),e(132,"."),i(),n(133,"br")(134,"div",1)(135,"br"),t(136,"p")(137,"b"),e(138,"Supervision"),i()(),n(139,"br"),t(140,"p"),e(141,"\u201CMultimodal AI for Art Authentication\u201D, master thesis supervision of Arda Batu D\xFCzg\xFCn."),i(),n(142,"br")(143,"div",1),i()())}});let o=a;return o})();var M=(()=>{let a=class a{};a.\u0275fac=function(r){return new(r||a)},a.\u0275cmp=l({type:a,selectors:[["app-about"]],standalone:!0,features:[c],decls:38,vars:0,consts:[[1,"row","justify-content-center","pt-4"],["width","100%","height","100%",1,"col-8",2,"border-style","dashed none none none","border-width","2px","border-color","lightgray"],[1,"row"],[1,"col-4"],["src","assets/images/photo.jpg","height","350","width","100%",2,"float","left","padding-top","30px","padding-bottom","20px"],[1,"col-8"],["href","https://dvstudies.net/"],[1,"material-icons-outlined"],["href","https://www.canva.com/design/DAGJzMXYtJc/dyxr9fWDl3tRb0SEe2Ay-g/view?utm_content=DAGJzMXYtJc&utm_campaign=designshare&utm_medium=link&utm_source=editor"]],template:function(r,d){r&1&&(t(0,"div",0)(1,"div",1)(2,"div",2)(3,"div",3),n(4,"img",4),i(),t(5,"div",5)(6,"p"),n(7,"br"),e(8," Hi! I am a PhD student at "),t(9,"a",6),e(10,"Digital Visual Studies"),i(),e(11,", a center between the Max Planck Society (MPG) and the University of Zurich (UZH) since March 2023. I hold a Bachelor\u2019s in Informatics from Amsterdam University College and I completed a Master\u2019s of Science in Digital Humanities Engineering at the Swiss Federal Institute of Technology of Lausanne (EPFL). Before joining DVS, I worked as a data scientist for insurance and academic publishing and as an AI developer in the art market. "),n(12,"br")(13,"br"),e(14," I'm interested in interdisciplinary research between the Arts and Artificial Intelligence. My main fields of research include disentanglement and concept-based generative AI, creative AI, critical computer vision, AI assisted art authentication and machinic curation of artistic and literary collections. "),n(15,"br")(16,"br"),e(17," I am a researcher that doesn't believe in disciplinary boundaries; a creator who sees art as a guide to the future and to reflection; a scientist in search for critiques; a person who is in love with the past but only thinks about the future. "),i()()()(),t(18,"div",1)(19,"p"),n(20,"br"),t(21,"span",7),e(22," email "),i(),e(23," ludovica.schaerf at gmail.com "),n(24,"br"),t(25,"span",7),e(26," phone "),i(),e(27," +41 779842115"),n(28,"br"),t(29,"span",7),e(30," location_on "),i(),e(31," Zurich, 8057, Switzerland "),n(32,"br"),t(33,"span",7),e(34," vertical_align_bottom "),i(),t(35,"a",8),e(36," Curriculum Vitae"),i()()(),n(37,"div",1),i())}});let o=a;return o})();var j=[{path:"",component:E},{path:"calvino",component:A},{path:"ai-curation",component:C},{path:"critical-ai",component:D},{path:"generative-ai",component:k},{path:"art-authentication",component:I},{path:"publications",component:T},{path:"about",component:M}];var F={providers:[w(j),v()]};var P={providers:[y()]},V=u(F,P);var L=()=>g(S,V),ue=L;export{ue as a};
