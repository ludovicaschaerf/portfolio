<!-- <embed src="https://neriiacopo.github.io/LatentSpaceNavigator/" style="width:100%; height: 40vw;"> -->
    <div class='row justify-content-center mt-5 pb-5' >
        <div class='col-8'>
            <img src="assets/images/colorwai.gif" style='float:left; padding-top:20px;' height=100% width=100%>
            <br>
            <!-- <p style='font-size:12px'>First slide of a presentation given at CUDAN 2023 explaining the theoretical grounding and 
            first methodology of the project.</p> -->
        </div>
    </div>
    
<div class='row justify-content-center'>
    <div class="col-8 col-md-3">
    <br>
    <h5 style='text-align:left;'>Augmenting Explainable AI <br>
        The Latent Space of Large Vision Models through Interpretative Artistic Dimensions
    </h5>

    <p style='text-align:left;'> This is my main project <br> for my PhD (2023-)  <br> at Digital Visual Studies (MPG-UZH) <br>
    </p>
    <div style='border-style: dashed none none none; border-width: 2px; border-color: lightgray;'>
        <br>
    </div>
    <!-- <img src="assets/images/textaile.png" style='padding-top:20px;' height=350 width=100%>
    <p style='font-size:12px'>Schematization of the disentangled directions in the latent space. The arrows indicate vectors of disentangled color directions, and the images are the textile samples generated by the model at those points. We see that movement in those directions yields appropriate changes in color. -->
    <!-- </p> -->
    <br>

</div>
<div class="col-8 col-md-5 ps-5">
    <div width=100% height=70%>
        <p style='text-align:left;'><br>
            <em>This is the project proposal for my PhD. The project aims to provide a framework to improve 
                understanding of the latent spaces of vision and text-vision generative models. I believe
                the spaces are filled with important information on the functioning of the models (the distorted lens
                of AI models) and on the cultural and societal appropriations of these models from their training 
                data. While latent space analyses have gained large popularity, there is still lots to discover on
                how to understand and exploit these spaces. Broadly speaking, it is aimed at providing an
                 interpretation of a selection of concepts related to artistic and design practices as represented
                  within the latent spaces of artificial intelligence models. 
                 </em><br><br> 

<b>Color Disentanglement of Textile Patterns</b>

We investigate the potential of the use of disentanglement to provide a - reductionist - understanding 
of abstract concepts in deep learning models. Disentanglement is defined in computer vision as the 
task of learning or identifying traversal directions in the latent space of models controlling 
only one factor of variation. The method is central to image manipulation techniques but is also
 used for explainable AI and style transfer.
We focus on the interpretative potential. We train several models (BetaVAE, StyleGAN3, 
Stable Diffusion) on the Metropolitan and the V&A textile collections to generate synthetic 
textile samples. 
The first aim is threefold. We first aim to correctly train at least one of the proposed models 
on a large enough dataset of textile patterns to be able to generate a variety of plausible synthetic
 textile samples. We secondly aim to enforce qualities that are crucial in textile pattern generation, 
 first and foremost, the repeat. The generated textile samples need to be suitable for 
 real-life printing and thus need to be stackable into a cloth, thus avoiding discontinuities
  in lateral and vertical stacking. Lastly, as in human textile sample generation, we need to be able
   to provide a colorway that accompanies each textile, where in addition to the base color of each 
   pattern, we can automatically adapt the pattern into 4 main color variations. We aim to achieve
    this latter using color disentanglement. We hypothesize that AI-based color manipulation may 
    yield colorways that respect - to some extent – color theory and color harmony principles but 
    enable larger variability, while image processing-based hue manipulation would only shift the 
    colors in a single direction.
Secondly, by finetuning these models on certain periods of time, such as the English textile scene
 of the post-London Expo of 1851 and 62, the Rubelli, Bevilacqua, and Fortuny Venetian textiles,
  or the Bauhaus textile artists and artisans, we aim to compare the difference in color generation
   and adaptation that are possible within these – partially - circumscribed frameworks. We, therefore,
    wish to use latent space navigation as a means of cultural and art historical investigation 
    on the consuetudes that link to color in each period. 
The combination of these two steps should help to augment explainable AI towards interpretable AI,
 where domain knowledge can be used to accompany observations. 

<br>
<b>Disentangled Abstractions or Verbalization Conditioning</b>

The recent hype for multimodal models gave rise to a novel entry point to latent spaces:
 language conditioning. While disentanglement is obtained backward from the image,
  and it is thus vision-first, text conditioning often stems from a pre-trained language 
  backbone and is thus language-first. This second part of the project focuses on qualifying 
  the technical and semantic differences between language conditioning and disentangled directions
   for image manipulation.
We first aim to survey and compare the different techniques that are visual-first from language-first, 
comparing their effect on the images and on the latent spaces of the models.
Arguably, art history is a narration of art through text, and, similarly, visual sketches, prints, 
and photographic reproductions are at the foundation of its study. In this part, 
we would like to investigate which salient elements of art can be conveyed to the machine 
and in art history, using language or visual abstractions. 

        </p>
    </div>
</div>

</div>
